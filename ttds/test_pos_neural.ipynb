{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdtscxqF09oT"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!pip install transformers\n",
        "sys.path.append('/content/drive/MyDrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM-OqKxQf916",
        "outputId": "7e94a7e5-5243-47b3-c4b9-1677769be54e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of Noun words: 71185 (78.26%)\n",
            "Num of Verb words: 13830 (15.20%)\n",
            "Num of Adj  words: 13445 (14.78%)\n",
            "Num of Adv  words: 3567 (3.92%)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from utils import *\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "word2pos, words_noun, words_verb, words_adj, words_adv = load_pos_from_json('/content/drive/MyDrive/word2pos.json')\n",
        "data, data_train, data_seen_500, data_unseen_500, data_test = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aAURqesRbJ2z"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/neural/final_model', 'rb') as f:\n",
        "    neural_model = pickle.load(f)\n",
        "    neural_model.eval()\n",
        "with open('/content/drive/MyDrive/neural/tokenizer', 'rb') as f:\n",
        "    neural_tokenizer = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/neural/name', 'rb') as f:\n",
        "    neural_y = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/neural/all-word2', 'rb') as f:\n",
        "    neural_X_embed = pickle.load(f)  # (117659, 768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bGLGSx_7AOhm"
      },
      "outputs": [],
      "source": [
        "seed =0\n",
        "num = 500\n",
        "noun_500 = np.random.RandomState(seed).choice(words_noun, num)\n",
        "verb_500 = np.random.RandomState(seed).choice(words_verb, num)\n",
        "adj_500 = np.random.RandomState(seed).choice(words_adj, num)\n",
        "adv_500 = np.random.RandomState(seed).choice(words_adv, num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvMjOLWGo4Ss"
      },
      "source": [
        "### Fit data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHqGQqmQo640",
        "outputId": "37195f99-088b-4264-bd19-9901bbedf9b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NearestNeighbors(metric='cosine')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit knn\n",
        "knn = NearestNeighbors(metric='cosine')\n",
        "knn.fit(neural_X_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K0qmdMC5pafS"
      },
      "outputs": [],
      "source": [
        "def mean_pooling(model_output, attention_mask):\n",
        "    # Mean Pooling - Take attention mask into account for correct averaging\n",
        "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "\n",
        "def get_embed(y_def, model, tokenizer):\n",
        "    # Tokenize sentences\n",
        "    encoded_input = tokenizer(y_def, padding=True, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**encoded_input)\n",
        "        # Perform pooling\n",
        "        sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "        # Normalize embeddings\n",
        "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
        "        return sentence_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH6-TKvxpEA7"
      },
      "source": [
        "### Noun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "narYw32opFYG",
        "outputId": "ef4f4c02-2043-4785-da64-ac82c6ead7f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 93218/93218 [03:25<00:00, 453.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc@1: 0.63\n",
            "acc@10: 0.73\n",
            "acc@100: 0.79\n",
            "median rank: 0\n",
            "standard error of mean rank: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.6271929824561403,\n",
              " 0.7324561403508771,\n",
              " 0.7916666666666666,\n",
              " 0.0,\n",
              " 17.192169264802914)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = []\n",
        "y_gold = []\n",
        "for word, defi in tqdm(data.items()):\n",
        "    if word in noun_500:\n",
        "        query = list(defi)[0]\n",
        "        query = get_embed(query, neural_model, neural_tokenizer)\n",
        "\n",
        "        prediction = search(query, knn, neural_y, n=1000)\n",
        "\n",
        "        y_pred.append(prediction)\n",
        "        y_gold.append(word)\n",
        "\n",
        "evaluate(y_pred, y_gold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PELBG68LpHdB"
      },
      "source": [
        "### Verb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgByBEfFyq5E",
        "outputId": "cbd3c61c-8717-4826-d6d1-f313c1935948"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 93218/93218 [03:26<00:00, 450.49it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc@1: 0.27\n",
            "acc@10: 0.36\n",
            "acc@100: 0.49\n",
            "median rank: 140\n",
            "standard error of mean rank: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.27114967462039047,\n",
              " 0.3579175704989154,\n",
              " 0.4945770065075922,\n",
              " 140.0,\n",
              " 22.26292442056393)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = []\n",
        "y_gold = []\n",
        "for word, defi in tqdm(data.items()):\n",
        "    if word in verb_500:\n",
        "        query = list(defi)[0]\n",
        "        query = get_embed(query, neural_model, neural_tokenizer)\n",
        "\n",
        "        prediction = search(query, knn, neural_y, n=1000)\n",
        "\n",
        "        y_pred.append(prediction)\n",
        "        y_gold.append(word)\n",
        "\n",
        "evaluate(y_pred, y_gold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCXlHekMoPKJ"
      },
      "source": [
        "### Adj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhJzKrhnqC1Y",
        "outputId": "e829400d-13ed-4cc6-84a6-40b1b1393ef3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 93218/93218 [03:36<00:00, 430.90it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc@1: 0.31\n",
            "acc@10: 0.43\n",
            "acc@100: 0.54\n",
            "median rank: 39\n",
            "standard error of mean rank: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.3050847457627119,\n",
              " 0.4322033898305085,\n",
              " 0.5444915254237288,\n",
              " 39.0,\n",
              " 21.540076115360776)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = []\n",
        "y_gold = []\n",
        "for word, defi in tqdm(data.items()):\n",
        "    if word in adj_500:\n",
        "        query = list(defi)[0]\n",
        "        query = get_embed(query, neural_model, neural_tokenizer)\n",
        "\n",
        "        prediction = search(query, knn, neural_y, n=1000)\n",
        "\n",
        "        y_pred.append(prediction)\n",
        "        y_gold.append(word)\n",
        "\n",
        "evaluate(y_pred, y_gold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Noun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDLEe6Z9Ac90",
        "outputId": "17953a6b-2918-4412-e016-de3fdb13d09c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 93218/93218 [02:46<00:00, 560.85it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc@1: 0.34\n",
            "acc@10: 0.48\n",
            "acc@100: 0.64\n",
            "median rank: 12\n",
            "standard error of mean rank: 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.3423913043478261,\n",
              " 0.4782608695652174,\n",
              " 0.6385869565217391,\n",
              " 12.5,\n",
              " 21.483948458261235)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = []\n",
        "y_gold = []\n",
        "for word, defi in tqdm(data.items()):\n",
        "    if word in adv_500:\n",
        "        query = list(defi)[0]\n",
        "        query = get_embed(query, neural_model, neural_tokenizer)\n",
        "\n",
        "        prediction = search(query, knn, neural_y, n=1000)\n",
        "\n",
        "        y_pred.append(prediction)\n",
        "        y_gold.append(word)\n",
        "\n",
        "evaluate(y_pred, y_gold)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "trained.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
