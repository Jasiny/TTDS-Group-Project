{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates how to evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103874/103874 [00:52<00:00, 1981.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from BM25Vectorizer import BM25Vectorizer\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "# don't forget to set clean=True to clean the data!\n",
    "data = load_data_from_json('data/data_with_augmented_examples.json', clean=True)\n",
    "data_test = load_data_from_json('data/test_200.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98481/98481 [03:12<00:00, 510.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8689479\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "data_train, data_seen_500, data_unseen_500 = split_seen_unseen(data)\n",
    "print(len(list(itertools.chain(*data_train.values()))))\n",
    "print(len(list(itertools.chain(*data_seen_500.values()))))\n",
    "print(len(list(itertools.chain(*data_unseen_500.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129297/129297 [00:00<00:00, 315206.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='cosine')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit BM25 vectorizer\n",
    "vectorizer = BM25Vectorizer(stop_words=None, stemmer=None, norm=False)\n",
    "X_BM25 = vectorizer.fit_transform(data_train) # <--- fit train data here\n",
    "words = vectorizer.words\n",
    "\n",
    "# fit knn\n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(X_BM25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test seen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [02:44<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.3\n",
      "acc@10: 0.61\n",
      "acc@100: 0.87\n",
      "median rank: 3\n",
      "standard error of mean rank: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3024193548387097,\n",
       " 0.6149193548387096,\n",
       " 0.8689516129032258,\n",
       " 3.0,\n",
       " 7.992881798306646)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_seen_500.items()): # <--- use seen_500 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 495/495 [02:44<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.23\n",
      "acc@10: 0.55\n",
      "acc@100: 0.82\n",
      "median rank: 7\n",
      "standard error of mean rank: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.23232323232323232,\n",
       " 0.5515151515151515,\n",
       " 0.8202020202020202,\n",
       " 7.0,\n",
       " 10.382158479706304)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_unseen_500.items()): # <--- use unseen_500 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test description set (200) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129297/129297 [00:00<00:00, 317002.60it/s]\n",
      "100%|██████████| 200/200 [01:07<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.01\n",
      "acc@10: 0.04\n",
      "acc@100: 0.32\n",
      "median rank: 230\n",
      "standard error of mean rank: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.005, 0.035, 0.315, 230.5, 27.220657759778693)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit BM25 vectorizer\n",
    "vectorizer = BM25Vectorizer(stop_words=None, stemmer=None, norm=False)\n",
    "X_BM25 = vectorizer.fit_transform(data) # <--- fit all data here\n",
    "words = vectorizer.words\n",
    "\n",
    "# fit knn\n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(X_BM25)\n",
    "\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_test.items()): # <--- use desc_200 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
