{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook demonstrates how to evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from TfidfVectorizer import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "data_test = load_data_from_json('data/test_200.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103874/103874 [00:03<00:00, 31574.02it/s]\n",
      "100%|██████████| 89656/89656 [00:11<00:00, 7596.22it/s] \n",
      "100%|██████████| 95105/95105 [00:22<00:00, 4144.20it/s] \n",
      "100%|██████████| 486/486 [01:02<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.1\n",
      "acc@10: 0.29\n",
      "acc@100: 0.57\n",
      "median rank: 61\n",
      "standard error of mean rank: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.102880658436214,\n",
       " 0.294238683127572,\n",
       " 0.5720164609053497,\n",
       " 61.0,\n",
       " 16.880152235877166)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data_from_json('data/data_5d.json', clean=True, use_examples=False)\n",
    "data_train, data_seen_500, data_unseen_500 = split_seen_unseen(data)\n",
    "\n",
    "# fit tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=None, stemmer=None, norm=False)\n",
    "X_tfidf = vectorizer.fit_transform(data_train) # <--- fit train data here\n",
    "words = vectorizer.words\n",
    "\n",
    "# fit knn\n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(X_tfidf)\n",
    "\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_unseen_500.items()): # <--- use unseen_500 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_5d with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103874/103874 [00:05<00:00, 20464.17it/s]\n",
      "100%|██████████| 90995/90995 [00:12<00:00, 7203.82it/s] \n",
      "100%|██████████| 96223/96223 [00:23<00:00, 4049.80it/s] \n",
      "100%|██████████| 488/488 [00:49<00:00,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.1\n",
      "acc@10: 0.3\n",
      "acc@100: 0.57\n",
      "median rank: 53\n",
      "standard error of mean rank: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09836065573770492,\n",
       " 0.29508196721311475,\n",
       " 0.5717213114754098,\n",
       " 53.0,\n",
       " 17.213963157183002)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data_from_json('data/data_5d.json', clean=True, use_examples=True)\n",
    "data_train, data_seen_500, data_unseen_500 = split_seen_unseen(data)\n",
    "\n",
    "# fit tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=None, stemmer=None, norm=False)\n",
    "X_tfidf = vectorizer.fit_transform(data_train) # <--- fit train data here\n",
    "words = vectorizer.words\n",
    "\n",
    "# fit knn\n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(X_tfidf)\n",
    "\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_unseen_500.items()): # <--- use unseen_500 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103874/103874 [00:05<00:00, 18255.25it/s]\n",
      "100%|██████████| 93218/93218 [00:15<00:00, 5848.81it/s] \n",
      "100%|██████████| 113050/113050 [00:28<00:00, 3955.37it/s] \n",
      "100%|██████████| 480/480 [00:58<00:00,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.13\n",
      "acc@10: 0.34\n",
      "acc@100: 0.64\n",
      "median rank: 44\n",
      "standard error of mean rank: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13125, 0.3416666666666667, 0.6375, 44.5, 15.419463639567038)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data_from_json('data/data.json', clean=True)\n",
    "data_train, data_seen_500, data_unseen_500 = split_seen_unseen(data)\n",
    "\n",
    "# fit tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=None, stemmer=None, norm=False)\n",
    "X_tfidf = vectorizer.fit_transform(data_train) # <--- fit train data here\n",
    "words = vectorizer.words\n",
    "\n",
    "# fit knn\n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(X_tfidf)\n",
    "\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_unseen_500.items()): # <--- use unseen_500 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_merged with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103874/103874 [00:05<00:00, 18163.59it/s]\n",
      "100%|██████████| 94452/94452 [00:16<00:00, 5784.74it/s] \n",
      "100%|██████████| 117034/117034 [00:30<00:00, 3861.19it/s] \n",
      "100%|██████████| 478/478 [01:02<00:00,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.1\n",
      "acc@10: 0.27\n",
      "acc@100: 0.51\n",
      "median rank: 90\n",
      "standard error of mean rank: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10460251046025104,\n",
       " 0.26778242677824265,\n",
       " 0.5125523012552301,\n",
       " 90.5,\n",
       " 18.960784146456554)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data_from_json('data/data_with_examples.json', clean=True)\n",
    "data_train, data_seen_500, data_unseen_500 = split_seen_unseen(data)\n",
    "\n",
    "# fit tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=None, stemmer=None, norm=False)\n",
    "X_tfidf = vectorizer.fit_transform(data_train) # <--- fit train data here\n",
    "words = vectorizer.words\n",
    "\n",
    "# fit knn\n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(X_tfidf)\n",
    "\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_unseen_500.items()): # <--- use unseen_500 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103874/103874 [00:50<00:00, 2054.64it/s]\n",
      "100%|██████████| 97369/97369 [02:46<00:00, 583.85it/s] \n",
      "100%|██████████| 125217/125217 [01:38<00:00, 1276.86it/s] \n",
      "100%|██████████| 492/492 [02:30<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.23\n",
      "acc@10: 0.5\n",
      "acc@100: 0.81\n",
      "median rank: 10\n",
      "standard error of mean rank: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.23373983739837398,\n",
       " 0.4959349593495935,\n",
       " 0.8089430894308943,\n",
       " 10.0,\n",
       " 9.64732386671763)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data_from_json('data/data_with_augmented.json', clean=True)\n",
    "data_train, data_seen_500, data_unseen_500 = split_seen_unseen(data)\n",
    "\n",
    "# fit tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=None, stemmer=None, norm=False)\n",
    "X_tfidf = vectorizer.fit_transform(data_train) # <--- fit train data here\n",
    "words = vectorizer.words\n",
    "\n",
    "# fit knn\n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(X_tfidf)\n",
    "\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_unseen_500.items()): # <--- use unseen_500 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_augmented with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103874/103874 [00:58<00:00, 1778.64it/s]\n",
      "100%|██████████| 98481/98481 [03:04<00:00, 535.14it/s] \n",
      "100%|██████████| 129297/129297 [01:53<00:00, 1143.36it/s] \n",
      "100%|██████████| 496/496 [03:01<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc@1: 0.25\n",
      "acc@10: 0.51\n",
      "acc@100: 0.77\n",
      "median rank: 8\n",
      "standard error of mean rank: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2540322580645161,\n",
       " 0.5100806451612904,\n",
       " 0.7701612903225806,\n",
       " 8.0,\n",
       " 9.746020237446324)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data_from_json('data/data_with_augmented_examples.json', clean=True)\n",
    "data_train, data_seen_500, data_unseen_500 = split_seen_unseen(data)\n",
    "\n",
    "# fit tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=None, stemmer=None, norm=False)\n",
    "X_tfidf = vectorizer.fit_transform(data_train) # <--- fit train data here\n",
    "words = vectorizer.words\n",
    "\n",
    "# fit knn\n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(X_tfidf)\n",
    "\n",
    "y_pred = []\n",
    "y_gold = []\n",
    "for word, defi in tqdm(data_unseen_500.items()): # <--- use unseen_500 data here\n",
    "    query = list(defi)[0]\n",
    "    query = vectorizer.transform(query)\n",
    "\n",
    "    prediction = search(query, knn, words, n=1000)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "    y_gold.append(word)\n",
    "\n",
    "evaluate(y_pred, y_gold)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
